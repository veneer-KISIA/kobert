{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./NIKL_NE_2022_v1.0/SXNE2202211218.json', 'r', encoding='utf-8') as f:\n",
    "    data_s = json.load(f)\n",
    "\n",
    "with open('./NIKL_NE_2022_v1.0/NXNE2202211218.json', 'r', encoding='utf-8') as f:\n",
    "    data_n = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, target=None) -> None:\n",
    "        self.label_set = set(['UNK'])\n",
    "        self.labels = []\n",
    "        self.sentences = []\n",
    "        self.target = target if target else []\n",
    "\n",
    "def create_data(data: Data, raw_data, filter=True):\n",
    "    for document in raw_data['document']:\n",
    "        doc_sentences = document['sentence']\n",
    "\n",
    "        sent = StringIO()\n",
    "        label = []\n",
    "        for words in doc_sentences:\n",
    "            # sentence\n",
    "            sent.write(words['form'].replace('|', ''))\n",
    "\n",
    "            # label\n",
    "            ne = words['NE']\n",
    "            words_length = len(words['word'])\n",
    "            new_ne = []\n",
    "\n",
    "            if filter:  # filters non target ne labels\n",
    "                for ne_item in ne:\n",
    "                    if ne_item['label'] in data.target:\n",
    "                        new_ne.append(ne_item)\n",
    "                ne = new_ne\n",
    "            \n",
    "            if not ne:\n",
    "                label.extend(['O'] * words_length)  # add O label\n",
    "\n",
    "            else:\n",
    "                ne_iter = iter(ne)\n",
    "                next_label = next(ne_iter)\n",
    "                \n",
    "                try:\n",
    "                    for i, word in enumerate(words['word'], 1):\n",
    "                        word_beg = word['begin']\n",
    "                        word_end = word['end']\n",
    "\n",
    "                        if next_label['begin'] <= word_end:  # reached label word\n",
    "                            if word_beg <= next_label['begin']:  # if word start of label\n",
    "                                label.append(f\"{next_label['label']}-B\")\n",
    "\n",
    "                            else:  # label is multiple words, but does not contain begining\n",
    "                                label.append(f\"{next_label['label']}-I\")\n",
    "\n",
    "                            if next_label['end'] <= word_end:  # end of label\n",
    "                                next_label = next(ne_iter)          \n",
    "                        else:\n",
    "                            label.append('O')\n",
    "\n",
    "                except StopIteration:\n",
    "                    label.extend(['O'] * (words_length - i))    \n",
    "  \n",
    "\n",
    "            # end of sentence\n",
    "            if words['form'].endswith('.') or words['form'].endswith('?') or words['form'].endswith('!'):\n",
    "                data.label_set.update(label)\n",
    "\n",
    "                data.sentences.append(sent.getvalue())\n",
    "                data.labels.append(' '.join(label))\n",
    "                sent = StringIO()  # new sentence\n",
    "                label = []             \n",
    "            else:\n",
    "                sent.write(' ')\n",
    "\n",
    "\n",
    "\n",
    "def write_data(data:Data, output_train, output_test, seed=None):\n",
    "    with open(output_train, 'w', encoding='utf-8') as f_train, open(output_test, 'w', encoding='utf-8') as f_test:\n",
    "        if seed:\n",
    "            random.seed(seed)\n",
    "        for s, l in zip(data.sentences, data.labels):\n",
    "            rand = random.random()\n",
    "            if rand < 0.8:\n",
    "                f_train.write(f'{s}\\t{l}\\n')\n",
    "            else:\n",
    "                f_test.write(f'{s}\\t{l}\\n')\n",
    "\n",
    "def write_labels(data, output_label):\n",
    "    label_list = list(data.label_set)\n",
    "    label_list.sort()\n",
    "\n",
    "    with open(output_label, 'w', encoding='utf-8') as f_label:\n",
    "        for lab in label_list:\n",
    "            f_label.write(f'{lab}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['PS_NAME', 'PS_PET', 'OGG_EDUCATION', 'OGG_MEDICAL', 'LCP_COUNTRY', 'LCP_PROVINCE', 'LCP_COUNTY', 'LCP_CITY', 'LCP_CAPITALCITY', 'QT_AGE', 'QT_ADDRESS', 'TMM_DISEASE', 'TMM_DRUG']\n",
    "data = Data(target=target)\n",
    "\n",
    "create_data(data, data_s, filter=True)\n",
    "create_data(data, data_n, filter=True)\n",
    "\n",
    "write_data(data, './data/train_reduced_label.tsv', './data/test_reduced_label.tsv', seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_labels(data, './data/reduced_label.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
